pomdp_model: /home/hind/catkin_ws/src/markov_decision_making/mdm_kuri_example/src/MAHRC_6x5_v3_3.dpomdp
policy_file: /home/hind/.madp/results/POMDP/MAHRC_6x5_v3_3/POMDP_MAHRC_6x5_v3_3
decision_horizon: 50
initial_action: stop_stop
initial_state: c_d_f_c
initial_state_belief: 1.0
observations: 
    - noVic_noDan_noVic_noDan
    - noVic_noDan_noVic_noDan
    - noVic_noDan_vic_noDan
    - noVic_noDan_noVic_noDan
    - noVic_noDan_noVic_noDan
    - noVic_noDan_noVic_noDan
    - noVic_noDan_noVic_noDan
    - noVic_noDan_noVic_noDan
    - noVic_noDan_noVic_noDan
    - noVic_noDan_noVic_noDan
